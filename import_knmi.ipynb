{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29761478",
   "metadata": {},
   "source": [
    "# Import KNMI data\n",
    "\n",
    "Reads in KNMI weather data and stores it in data/src/knmi.csv .\n",
    "\n",
    "Run this file before running generate_ice_cream_sales.ipynb\n",
    "\n",
    "\n",
    "\n",
    "https://www.daggegevens.knmi.nl/klimatologie/daggegevens?start=20220101&end=20241231&vars=TG:TN:TX:SQ:DR:RH:NG&stns[260]=1&fmt=csv\n",
    "\n",
    "Variables:\n",
    "\n",
    "- **TG**: Etmaalgemiddelde temperatuur\n",
    "- **TN**: TN: Minimum temperatuur (in 0.1 graden Celsius)\n",
    "- **TX**: Maximum temperatuur (in 0.1 graden Celsius)\n",
    "- **SQ**: Zonneschijnduur (in 0.1 uur) berekend uit de globale straling (-1 voor <0.05 uur)\n",
    "- **DR**: Duur van de neerslag (in 0.1 uur)\n",
    "- **RH**: Etmaalsom van de neerslag (in 0.1 mm) (-1 voor <0.05 mm)\n",
    "- **NG**: Etmaalgemiddelde bewolking (bedekkingsgraad van de bovenlucht in achtsten, 9=bovenlucht onzichtbaar)\n",
    "\n",
    "Stations:\n",
    "\n",
    "- **260**: de Bilt. Other stations do not always have all data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71569cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import urllib.request # For reading from URLs\n",
    "import urllib.error # For reading from URLs\n",
    "import io # For reading CSV data from a string.\n",
    "import datetime # For generating timestamps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc0a94c",
   "metadata": {},
   "source": [
    "## Import the KNMI source data\n",
    "\n",
    "First, import the raw KNMI source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db94aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the csv url and import the raw data.\n",
    "\n",
    "# Settings. Change as needed. See top of notebook for information on fields.\n",
    "start = '20220101'\n",
    "end = '20241231'\n",
    "stations = [260]\n",
    "fields = ['TG',\n",
    "          'TN',\n",
    "          'TX',\n",
    "          'SQ',\n",
    "          'DR',\n",
    "          'RH',\n",
    "          'NG'\n",
    "          ]\n",
    "base_url = 'https://www.daggegevens.knmi.nl/klimatologie/daggegevens'\n",
    "\n",
    "num_lines_to_skip = 14 # KNMI adds information to the top of the file. Trial and error has shown that there are 14 lines of this stuff.\n",
    "\n",
    "url = base_url + '?' + 'start=' + start + '&end=' + end\n",
    "\n",
    "url += '&stns=' + ':'.join([str(station) for station in stations])\n",
    "\n",
    "# stnlist = ['stsns[' + str(stsn) + ']=1' for stsn in stations]\n",
    "# url += '&' + '&'.join(stnlist)\n",
    "\n",
    "url += '&vars=' + ':'.join(fields)\n",
    "\n",
    "url += '&fmt=csv'\n",
    "\n",
    "print(url)\n",
    "\n",
    "# Simply calling pd.read_csv on the url does not work, we have to\n",
    "# read in the CSV data manually from the URL and then parse it.\n",
    "\n",
    "csv_source = ''\n",
    "try:\n",
    "   with urllib.request.urlopen(url) as f:\n",
    "      csv_source = f.read().decode('utf-8')\n",
    "    #   print(f.read().decode('utf-8'))\n",
    "except urllib.error.URLError as e:\n",
    "    print(e.reason)\n",
    "\n",
    "# Turn the source data into a proper CSV file and store it (for logging reasons).\n",
    "df_raw = pd.read_csv(io.StringIO(csv_source), skiprows=num_lines_to_skip, on_bad_lines='warn')\n",
    "df_raw.to_csv('data/src/knmi-import-' + \n",
    "              '-'.join(str(station) for station in stations) + \n",
    "              '_' + start + '-' + end + \n",
    "              datetime.datetime.now().strftime('%Y%m%d.%H.%M.%S'),\n",
    "              index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f21e4c",
   "metadata": {},
   "source": [
    "## Process the KNMI source data\n",
    "\n",
    "Turn the KNMI source data into something we can use. Map column names to names that are more readable and do some basic feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d231ce",
   "metadata": {},
   "source": [
    "### Rename columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09551977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What should fields be renamed to?\n",
    "# The header row reads: # STN,YYYYMMDD,   TG,   TN,   TX,   SQ,   DR,   RH,   NG\n",
    "translation_map = {\n",
    "    '# STN' : 'station',\n",
    "    'YYYYMMDD' : 'date',\n",
    "    '   TG' : 'temp_avg',\n",
    "    '   TN' : 'temp_min',\n",
    "    '   TX' : 'temp_max',\n",
    "    '   SQ' : 'sun_hr',\n",
    "    '   DR' : 'rain_hr',\n",
    "    '   RH' : 'rain_total_mm',\n",
    "    '   NG' : 'cloud_cover_perc'\n",
    "}\n",
    "df_clean = df_raw.rename(columns=translation_map).copy()\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5477699a",
   "metadata": {},
   "source": [
    "### Change units\n",
    "\n",
    "Some columns have units that require explanation. Better to use units that make sense - and that match what the new headers say."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcea171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperatures are in 0.1 C. Turn them into C.\n",
    "for temp_col in ['temp_avg', 'temp_min', 'temp_max']:\n",
    "    df_clean[temp_col] = df_clean[temp_col] / 10\n",
    "\n",
    "# Sun hours and rain hours are in 0.1 hour. Turn them into hours.\n",
    "for hr_col in ['sun_hr', 'rain_hr']:\n",
    "    df_clean[hr_col] = df_clean[hr_col] / 10\n",
    "\n",
    "# Rain total is in 0.1 mm. Turn it into mm.\n",
    "for mm_col in ['rain_total_mm']:\n",
    "    df_clean[mm_col] = df_clean[mm_col] / 10\n",
    "\n",
    "# Cloud cover is in 1/8th, with 9 being \"cover complete\".\n",
    "# Let's decide that both 8 and 9 are 100\n",
    "df_clean['cloud_cover_perc'] = df_clean['cloud_cover_perc'].map(lambda x : 1 if x >= 8  else x / 8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2028318d",
   "metadata": {},
   "source": [
    "# Fix values\n",
    "\n",
    "Some columns have odd values that are used to signal special circumstances. Since this course is not about data cleaning, turn those values into values that are more meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ccac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 means: less than 0.05 hr. Just make it 0\n",
    "df_clean['sun_hr'] = df_clean['sun_hr'].map(lambda x : 0 if x < 0 else x)\n",
    "\n",
    "# -1 means: less than 0.05 mm. Just make it 0\n",
    "df_clean['rain_total_mm'] = df_clean['rain_total_mm'].map(lambda x : 0 if x < 0 else x)\n",
    "\n",
    "# Dates are in YYYYMMDD format. Turn them into something Pandas recognizes as dates.\n",
    "df_clean['date'] = pd.to_datetime(df_clean['date'], format='%Y%m%d')\n",
    "\n",
    "df_clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ad435",
   "metadata": {},
   "source": [
    "## Drop the station column and save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550f7825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns=['station']).to_csv('data/src/knmi-processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
